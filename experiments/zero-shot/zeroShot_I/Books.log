(Recformer) admin@lablinux:~/Elaine/RecFormer$ time python zero-shot.py --pretrain_ckpt /home/admin/Elaine/RecFormer/pretrain_ckpt/recformer_seqrec_ckpt.bin --data_path /home/admin/Elaine/RecFormer/finetune_data/dataset/meta/Books --num_train_epochs 128 --batch_size 16 --device 0 --fp16 --finetune_negative_sample_size -1 > /home/admin/Elaine/RecFormer/zeroShot_I/Books.log 2>&1

real    0m9.219s
user    0m8.590s
sys     0m7.625s

Global seed set to 42
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'LongformerTokenizer'. 
The class this function is called from is 'RecformerTokenizer'.
Namespace(pretrain_ckpt='/home/admin/Elaine/RecFormer/pretrain_ckpt/recformer_seqrec_ckpt.bin', data_path='/home/admin/Elaine/RecFormer/finetune_data/dataset/meta/Books', output_dir='checkpoints', ckpt='best_model.bin', model_name_or_path='allenai/longformer-base-4096', train_file='train.json', dev_file='val.json', test_file='test.json', item2id_file='smap.json', meta_file='meta_data.json', preprocessing_num_workers=8, dataloader_num_workers=0, temp=0.05, num_train_epochs=128, gradient_accumulation_steps=8, finetune_negative_sample_size=-1, metric_ks=[10, 50], batch_size=16, learning_rate=5e-05, weight_decay=0, warmup_steps=100, device=0, fp16=True, fix_word_embedding=False, verbose=3)
Loading attribute data /home/admin/Elaine/RecFormer/finetune_data/dataset/meta/Books

[Tokenize] /home/admin/Elaine/RecFormer/finetune_data/dataset/meta/Books:   0%| | 0/53 [00:00<?, ?it/s]
[Tokenize] /home/admin/Elaine/RecFormer/finetune_data/dataset/meta/Books: 100%|█| 53/53 [00:00<00:00, 7
Successfully load 53 tokenized items.
Encoding items.

Encode all items:   0%|                                                       | 0/4 [00:00<?, ?it/s]/home/admin/anaconda3/envs/Recformer/lib/python3.10/site-packages/transformers/modeling_utils.py:862: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(

Encode all items:  25%|███████████▊                                   | 1/4 [00:00<00:00,  3.53it/s]
Encode all items:  75%|███████████████████████████████████▎           | 3/4 [00:00<00:00,  8.56it/s]
Encode all items: 100%|███████████████████████████████████████████████| 4/4 [00:00<00:00,  8.73it/s]
Initalize item embeddings from vectors.

Evaluate:   0%|                                                              | 0/15 [00:00<?, ?it/s]
Evaluate:  13%|███████▏                                              | 2/15 [00:00<00:00, 16.72it/s]
Evaluate:  27%|██████████████▍                                       | 4/15 [00:00<00:00, 16.86it/s]
Evaluate:  40%|█████████████████████▌                                | 6/15 [00:00<00:00, 16.91it/s]
Evaluate:  53%|████████████████████████████▊                         | 8/15 [00:00<00:00, 16.94it/s]
Evaluate:  67%|███████████████████████████████████▎                 | 10/15 [00:00<00:00, 16.96it/s]
Evaluate:  80%|██████████████████████████████████████████▍          | 12/15 [00:00<00:00, 16.98it/s]
Evaluate:  93%|█████████████████████████████████████████████████▍   | 14/15 [00:00<00:00, 16.98it/s]
Evaluate: 100%|█████████████████████████████████████████████████████| 15/15 [00:00<00:00, 16.91it/s]
torch.Size([1, 53])
torch.Size([])
Test set: {'NDCG@10': 0.9958333333333333, 'Recall@10': 0.9958333333333333, 'NDCG@50': 0.9965716004371643, 'Recall@50': 1.0, 'MRR': 0.9959183692932129, 'AUC': 0.996226414044698}
